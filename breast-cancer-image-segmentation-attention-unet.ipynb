{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **Introduction**","metadata":{}},{"cell_type":"markdown","source":"# **Imports**","metadata":{"id":"g_3rM2Af6CwS"}},{"cell_type":"code","source":"from IPython.display import clear_output\n!pip install tf_explain\nclear_output()","metadata":{"id":"ni0qxGc3L1bu","execution":{"iopub.status.busy":"2022-09-05T03:01:34.482836Z","iopub.execute_input":"2022-09-05T03:01:34.48354Z","iopub.status.idle":"2022-09-05T03:01:46.062539Z","shell.execute_reply.started":"2022-09-05T03:01:34.483427Z","shell.execute_reply":"2022-09-05T03:01:46.061242Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# common\nimport os\nimport keras\nimport numpy as np\nimport pandas as pd\nfrom glob import glob\nimport tensorflow as tf\nimport tensorflow.image as tfi\n\n# Data\nfrom keras.preprocessing.image import load_img, img_to_array\nfrom tensorflow.keras.utils import to_categorical\n\n# Data Viz\nimport matplotlib.pyplot as plt\n\n# Model \nfrom keras.models import Model\nfrom keras.layers import Layer\nfrom keras.layers import Conv2D\nfrom keras.layers import Dropout\nfrom keras.layers import UpSampling2D\nfrom keras.layers import concatenate\nfrom keras.layers import Add\nfrom keras.layers import Multiply\nfrom keras.layers import Input\nfrom keras.layers import MaxPool2D\nfrom keras.layers import BatchNormalization\n\n# Callbacks \nfrom keras.callbacks import Callback\nfrom keras.callbacks import EarlyStopping\nfrom keras.callbacks import ModelCheckpoint\nfrom tf_explain.core.grad_cam import GradCAM\n\n# Metrics\nfrom keras.metrics import MeanIoU","metadata":{"id":"4zXw8Ycj6D0l","execution":{"iopub.status.busy":"2022-09-05T03:01:46.064835Z","iopub.execute_input":"2022-09-05T03:01:46.065613Z","iopub.status.idle":"2022-09-05T03:01:51.8092Z","shell.execute_reply.started":"2022-09-05T03:01:46.065561Z","shell.execute_reply":"2022-09-05T03:01:51.808145Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Data**","metadata":{"id":"8zckEunbDxLy"}},{"cell_type":"code","source":"def load_image(image, SIZE):\n    return np.round(tfi.resize(img_to_array(load_img(image))/255.,(SIZE, SIZE)),4)\n\ndef load_images(image_paths, SIZE, mask=False, trim=None):\n    if trim is not None:\n        image_paths = image_paths[:trim]\n    \n    if mask:\n        images = np.zeros(shape=(len(image_paths), SIZE, SIZE, 1))\n    else:\n        images = np.zeros(shape=(len(image_paths), SIZE, SIZE, 3))\n    \n    for i,image in enumerate(image_paths):\n        img = load_image(image,SIZE)\n        if mask:\n            images[i] = img[:,:,:1]\n        else:\n            images[i] = img\n    \n    return images","metadata":{"id":"Sv5MB-unO3tY","execution":{"iopub.status.busy":"2022-09-05T03:01:51.811434Z","iopub.execute_input":"2022-09-05T03:01:51.812416Z","iopub.status.idle":"2022-09-05T03:01:51.820192Z","shell.execute_reply.started":"2022-09-05T03:01:51.812376Z","shell.execute_reply":"2022-09-05T03:01:51.819217Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def show_image(image, title=None, cmap=None, alpha=1):\n    plt.imshow(image, cmap=cmap, alpha=alpha)\n    if title is not None:\n        plt.title(title)\n    plt.axis('off')\n\ndef show_mask(image, mask, cmap=None, alpha=0.4):\n    plt.imshow(image)\n    plt.imshow(tf.squeeze(mask), cmap=cmap, alpha=alpha)\n    plt.axis('off')","metadata":{"id":"PiQzRTMlnNAH","execution":{"iopub.status.busy":"2022-09-05T03:01:51.822457Z","iopub.execute_input":"2022-09-05T03:01:51.823162Z","iopub.status.idle":"2022-09-05T03:01:51.83941Z","shell.execute_reply.started":"2022-09-05T03:01:51.823116Z","shell.execute_reply":"2022-09-05T03:01:51.838506Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"SIZE = 256","metadata":{"id":"1BVzD2xgFkgt","execution":{"iopub.status.busy":"2022-09-05T03:01:51.842062Z","iopub.execute_input":"2022-09-05T03:01:51.843276Z","iopub.status.idle":"2022-09-05T03:01:51.849482Z","shell.execute_reply.started":"2022-09-05T03:01:51.843237Z","shell.execute_reply":"2022-09-05T03:01:51.848375Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"root_path = '../input/breast-ultrasound-images-dataset/Dataset_BUSI_with_GT/'\nclasses = sorted(os.listdir(root_path))\nclasses","metadata":{"id":"wP8jF-PHO9Ch","outputId":"f8dc581b-0a21-494b-8a74-73ce6fe5b9a3","execution":{"iopub.status.busy":"2022-09-05T03:01:51.850897Z","iopub.execute_input":"2022-09-05T03:01:51.851351Z","iopub.status.idle":"2022-09-05T03:01:51.870184Z","shell.execute_reply.started":"2022-09-05T03:01:51.851316Z","shell.execute_reply":"2022-09-05T03:01:51.869055Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"single_mask_paths = sorted([sorted(glob(root_path + name + \"/*mask.png\")) for name in classes])\ndouble_mask_paths = sorted([sorted(glob(root_path + name + \"/*mask_1.png\")) for name in classes])","metadata":{"id":"gVbNZJujO8_K","execution":{"iopub.status.busy":"2022-09-05T03:01:51.871752Z","iopub.execute_input":"2022-09-05T03:01:51.872095Z","iopub.status.idle":"2022-09-05T03:01:52.237175Z","shell.execute_reply.started":"2022-09-05T03:01:51.872062Z","shell.execute_reply":"2022-09-05T03:01:52.236207Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_paths = []\nmask_paths = []\nfor class_path in single_mask_paths:\n    for path in class_path:\n        img_path = path.replace('_mask','')\n        image_paths.append(img_path)\n        mask_paths.append(path)","metadata":{"id":"hizq3EyITaeI","execution":{"iopub.status.busy":"2022-09-05T03:01:52.239503Z","iopub.execute_input":"2022-09-05T03:01:52.240195Z","iopub.status.idle":"2022-09-05T03:01:52.24625Z","shell.execute_reply.started":"2022-09-05T03:01:52.240157Z","shell.execute_reply":"2022-09-05T03:01:52.245286Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"show_image(load_image(image_paths[0], SIZE))","metadata":{"id":"RYwn8wnqTpa4","outputId":"35a2e47f-35bd-4cf8-f0c0-a1ccbbc78396","execution":{"iopub.status.busy":"2022-09-05T03:01:52.247792Z","iopub.execute_input":"2022-09-05T03:01:52.248193Z","iopub.status.idle":"2022-09-05T03:01:55.27378Z","shell.execute_reply.started":"2022-09-05T03:01:52.248159Z","shell.execute_reply":"2022-09-05T03:01:55.272487Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"show_mask(load_image(image_paths[0], SIZE), load_image(mask_paths[0], SIZE)[:,:,0], alpha=0.6)","metadata":{"id":"1G1w3V66UyPC","outputId":"dd8acb8a-0f2d-4885-fd7a-052e0a36044a","execution":{"iopub.status.busy":"2022-09-05T03:01:55.280056Z","iopub.execute_input":"2022-09-05T03:01:55.284839Z","iopub.status.idle":"2022-09-05T03:01:55.639848Z","shell.execute_reply.started":"2022-09-05T03:01:55.284784Z","shell.execute_reply":"2022-09-05T03:01:55.638815Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **Approach**","metadata":{"id":"pIjk4Ps8RDvW"}},{"cell_type":"markdown","source":"Below here I have explained my strategy to tackel the multiple mask Images.","metadata":{"id":"6KgLQ53URF5X"}},{"cell_type":"code","source":"show_image(load_image('../input/breast-ultrasound-images-dataset/Dataset_BUSI_with_GT/benign/benign (100).png', SIZE))","metadata":{"id":"64r6IQglO881","outputId":"0746c333-d114-4e2e-c8c6-99260f5ea934","execution":{"iopub.status.busy":"2022-09-05T03:01:55.641121Z","iopub.execute_input":"2022-09-05T03:01:55.64203Z","iopub.status.idle":"2022-09-05T03:01:55.784943Z","shell.execute_reply.started":"2022-09-05T03:01:55.641981Z","shell.execute_reply":"2022-09-05T03:01:55.783613Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"show_image(load_image('../input/breast-ultrasound-images-dataset/Dataset_BUSI_with_GT/benign/benign (100)_mask_1.png', SIZE))","metadata":{"id":"RS3v3F9wO86k","outputId":"8344b3b9-2fb3-4c7f-fed2-37420ff66b6a","execution":{"iopub.status.busy":"2022-09-05T03:01:55.786867Z","iopub.execute_input":"2022-09-05T03:01:55.78724Z","iopub.status.idle":"2022-09-05T03:01:55.911419Z","shell.execute_reply.started":"2022-09-05T03:01:55.787203Z","shell.execute_reply":"2022-09-05T03:01:55.910011Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"show_image(load_image('../input/breast-ultrasound-images-dataset/Dataset_BUSI_with_GT/benign/benign (100)_mask.png', SIZE))","metadata":{"id":"J7IujS3sPhst","outputId":"7e6a05b7-9039-423a-c8f1-db709be2c762","execution":{"iopub.status.busy":"2022-09-05T03:01:55.913537Z","iopub.execute_input":"2022-09-05T03:01:55.913943Z","iopub.status.idle":"2022-09-05T03:01:56.050891Z","shell.execute_reply.started":"2022-09-05T03:01:55.913905Z","shell.execute_reply":"2022-09-05T03:01:56.049403Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"I don't want the data this way, as both the masks belongs to the same class. A better idea can be to merge both these images","metadata":{"id":"68dZSoJ6PkSf"}},{"cell_type":"code","source":"img = np.zeros((1,SIZE,SIZE,3))\nmask1 = load_image('../input/breast-ultrasound-images-dataset/Dataset_BUSI_with_GT/benign/benign (100)_mask_1.png', SIZE)\nmask2 = load_image('../input/breast-ultrasound-images-dataset/Dataset_BUSI_with_GT/benign/benign (100)_mask.png', SIZE)\n\nimg = img + mask1 + mask2\nimg = img[0,:,:,0]\nshow_image(img, cmap='gray')","metadata":{"id":"FhVS-PhZPhqP","outputId":"8a8ed1e8-32c3-424b-d762-c4f597c4297c","execution":{"iopub.status.busy":"2022-09-05T03:01:56.052785Z","iopub.execute_input":"2022-09-05T03:01:56.053129Z","iopub.status.idle":"2022-09-05T03:01:56.185001Z","shell.execute_reply.started":"2022-09-05T03:01:56.053095Z","shell.execute_reply":"2022-09-05T03:01:56.183861Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We first merged them and them simple used the 1st channel because that is enough.","metadata":{"id":"O942E22FRNP3"}},{"cell_type":"code","source":"show_image(load_image('../input/breast-ultrasound-images-dataset/Dataset_BUSI_with_GT/benign/benign (100).png', SIZE))\nplt.imshow(img, cmap='binary', alpha=0.4)\nplt.axis('off')\nplt.show()","metadata":{"id":"YHPoLXTFP4C6","outputId":"90776d7f-a6e2-45f3-c7c9-197e1ff2873a","execution":{"iopub.status.busy":"2022-09-05T03:01:56.186807Z","iopub.execute_input":"2022-09-05T03:01:56.18767Z","iopub.status.idle":"2022-09-05T03:01:56.360032Z","shell.execute_reply.started":"2022-09-05T03:01:56.187632Z","shell.execute_reply":"2022-09-05T03:01:56.359079Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"show_image(load_image('../input/breast-ultrasound-images-dataset/Dataset_BUSI_with_GT/benign/benign (100).png', SIZE))\nplt.imshow(img, cmap='gray', alpha=0.4)\nplt.axis('off')\nplt.show()","metadata":{"id":"On868uBCP5Jj","outputId":"24cc41be-cc61-42f7-dcd2-525ee6289f92","execution":{"iopub.status.busy":"2022-09-05T03:01:56.361822Z","iopub.execute_input":"2022-09-05T03:01:56.362513Z","iopub.status.idle":"2022-09-05T03:01:56.518954Z","shell.execute_reply.started":"2022-09-05T03:01:56.36246Z","shell.execute_reply":"2022-09-05T03:01:56.51779Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"show_image(load_image('../input/breast-ultrasound-images-dataset/Dataset_BUSI_with_GT/benign/benign (100).png', SIZE))\nplt.imshow(img, alpha=0.4)\nplt.axis('off')\nplt.show()","metadata":{"id":"gXt6YcqKP5Gu","outputId":"19afe93f-e15b-4065-bbdc-90d4583ff33c","execution":{"iopub.status.busy":"2022-09-05T03:01:56.523975Z","iopub.execute_input":"2022-09-05T03:01:56.526191Z","iopub.status.idle":"2022-09-05T03:01:56.693508Z","shell.execute_reply.started":"2022-09-05T03:01:56.526153Z","shell.execute_reply":"2022-09-05T03:01:56.692534Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"This is how it looks with different cmaps. But you can drop them as then are very less in number (i.e 16) and this will not affect training much.","metadata":{"id":"rGkJpMajRXuK"}},{"cell_type":"markdown","source":"## **Data Work**","metadata":{"id":"PR-k_kiIRc5o"}},{"cell_type":"code","source":"images = load_images(image_paths, SIZE)\nmasks = load_images(mask_paths, SIZE, mask=True)","metadata":{"id":"NuDIR8PFP5EW","execution":{"iopub.status.busy":"2022-09-05T03:01:56.69498Z","iopub.execute_input":"2022-09-05T03:01:56.695622Z","iopub.status.idle":"2022-09-05T03:02:21.829549Z","shell.execute_reply.started":"2022-09-05T03:01:56.695572Z","shell.execute_reply":"2022-09-05T03:02:21.828515Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(13,8))\nfor i in range(15):\n    plt.subplot(3,5,i+1)\n    id = np.random.randint(len(images))\n    show_mask(images[id], masks[id], cmap='jet')\nplt.tight_layout()\nplt.show()","metadata":{"id":"Labwwn3nZnoy","outputId":"63b55df1-d389-45d4-925e-2bf9b40da21b","execution":{"iopub.status.busy":"2022-09-05T03:02:21.83113Z","iopub.execute_input":"2022-09-05T03:02:21.83152Z","iopub.status.idle":"2022-09-05T03:02:22.995772Z","shell.execute_reply.started":"2022-09-05T03:02:21.831463Z","shell.execute_reply":"2022-09-05T03:02:22.994916Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(13,8))\nfor i in range(15):\n    plt.subplot(3,5,i+1)\n    id = np.random.randint(len(images))\n    show_mask(images[id], masks[id], cmap='binary')\nplt.tight_layout()\nplt.show()","metadata":{"id":"hZJQ_FW5azlN","outputId":"c572ba10-870f-4718-fedd-caa7f1b42dbd","execution":{"iopub.status.busy":"2022-09-05T03:02:22.998098Z","iopub.execute_input":"2022-09-05T03:02:22.998923Z","iopub.status.idle":"2022-09-05T03:02:24.463297Z","shell.execute_reply.started":"2022-09-05T03:02:22.998876Z","shell.execute_reply":"2022-09-05T03:02:24.462125Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(13,8))\nfor i in range(15):\n    plt.subplot(3,5,i+1)\n    id = np.random.randint(len(images))\n    show_mask(images[id], masks[id], cmap='afmhot')\nplt.tight_layout()\nplt.show()","metadata":{"id":"RCtDRXrmazie","outputId":"5d93cb38-a1a7-47e2-b470-c12615ff3855","execution":{"iopub.status.busy":"2022-09-05T03:02:24.464957Z","iopub.execute_input":"2022-09-05T03:02:24.465423Z","iopub.status.idle":"2022-09-05T03:02:25.59319Z","shell.execute_reply.started":"2022-09-05T03:02:24.465381Z","shell.execute_reply":"2022-09-05T03:02:25.592124Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(13,8))\nfor i in range(15):\n    plt.subplot(3,5,i+1)\n    id = np.random.randint(len(images))\n    show_mask(images[id], masks[id], cmap='copper')\nplt.tight_layout()\nplt.show()","metadata":{"id":"5BIfKdeRazf_","outputId":"5d0db459-8ba3-4884-c20d-0ef80d5de368","execution":{"iopub.status.busy":"2022-09-05T03:02:25.594906Z","iopub.execute_input":"2022-09-05T03:02:25.595886Z","iopub.status.idle":"2022-09-05T03:02:26.695234Z","shell.execute_reply.started":"2022-09-05T03:02:25.595854Z","shell.execute_reply":"2022-09-05T03:02:26.69414Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Encoder**","metadata":{"id":"W6XkXzkHHcCp"}},{"cell_type":"code","source":"class EncoderBlock(Layer):\n\n    def __init__(self, filters, rate, pooling=True, **kwargs):\n        super(EncoderBlock, self).__init__(**kwargs)\n\n        self.filters = filters\n        self.rate = rate\n        self.pooling = pooling\n\n        self.c1 = Conv2D(filters, kernel_size=3, strides=1, padding='same', activation='relu', kernel_initializer='he_normal')\n        self.drop = Dropout(rate)\n        self.c2 = Conv2D(filters, kernel_size=3, strides=1, padding='same', activation='relu', kernel_initializer='he_normal')\n        self.pool = MaxPool2D()\n\n    def call(self, X):\n        x = self.c1(X)\n        x = self.drop(x)\n        x = self.c2(x)\n        if self.pooling:\n            y = self.pool(x)\n            return y, x\n        else:\n            return x\n\n    def get_config(self):\n        base_config = super().get_config()\n        return {\n            **base_config,\n            \"filters\":self.filters,\n            'rate':self.rate,\n            'pooling':self.pooling\n        }","metadata":{"id":"GQksNZycb_Xu","execution":{"iopub.status.busy":"2022-09-05T03:02:26.698904Z","iopub.execute_input":"2022-09-05T03:02:26.699313Z","iopub.status.idle":"2022-09-05T03:02:26.710779Z","shell.execute_reply.started":"2022-09-05T03:02:26.699276Z","shell.execute_reply":"2022-09-05T03:02:26.709289Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Decoder**","metadata":{}},{"cell_type":"code","source":"class DecoderBlock(Layer):\n\n    def __init__(self, filters, rate, **kwargs):\n        super(DecoderBlock, self).__init__(**kwargs)\n\n        self.filters = filters\n        self.rate = rate\n\n        self.up = UpSampling2D()\n        self.net = EncoderBlock(filters, rate, pooling=False)\n\n    def call(self, X):\n        X, skip_X = X\n        x = self.up(X)\n        c_ = concatenate([x, skip_X])\n        x = self.net(c_)\n        return x\n\n    def get_config(self):\n        base_config = super().get_config()\n        return {\n            **base_config,\n            \"filters\":self.filters,\n            'rate':self.rate,\n        }","metadata":{"id":"L_9pZ82jHJsG","execution":{"iopub.status.busy":"2022-09-05T03:02:26.712045Z","iopub.execute_input":"2022-09-05T03:02:26.712856Z","iopub.status.idle":"2022-09-05T03:02:26.723339Z","shell.execute_reply.started":"2022-09-05T03:02:26.712825Z","shell.execute_reply":"2022-09-05T03:02:26.722409Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Attention Gate**","metadata":{}},{"cell_type":"code","source":"class AttentionGate(Layer):\n\n    def __init__(self, filters, bn, **kwargs):\n        super(AttentionGate, self).__init__(**kwargs)\n\n        self.filters = filters\n        self.bn = bn\n\n        self.normal = Conv2D(filters, kernel_size=3, padding='same', activation='relu', kernel_initializer='he_normal')\n        self.down = Conv2D(filters, kernel_size=3, strides=2, padding='same', activation='relu', kernel_initializer='he_normal')\n        self.learn = Conv2D(1, kernel_size=1, padding='same', activation='sigmoid')\n        self.resample = UpSampling2D()\n        self.BN = BatchNormalization()\n\n    def call(self, X):\n        X, skip_X = X\n\n        x = self.normal(X)\n        skip = self.down(skip_X)\n        x = Add()([x, skip])\n        x = self.learn(x)\n        x = self.resample(x)\n        f = Multiply()([x, skip_X])\n        if self.bn:\n            return self.BN(f)\n        else:\n            return f\n        # return f\n\n    def get_config(self):\n        base_config = super().get_config()\n        return {\n            **base_config,\n            \"filters\":self.filters,\n            \"bn\":self.bn\n        }","metadata":{"id":"QG5cCor3JiaS","execution":{"iopub.status.busy":"2022-09-05T03:02:26.724616Z","iopub.execute_input":"2022-09-05T03:02:26.725865Z","iopub.status.idle":"2022-09-05T03:02:26.737361Z","shell.execute_reply.started":"2022-09-05T03:02:26.725828Z","shell.execute_reply":"2022-09-05T03:02:26.736385Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Custom Callback**","metadata":{}},{"cell_type":"code","source":"class ShowProgress(Callback):\n    def on_epoch_end(self, epochs, logs=None):\n        id = np.random.randint(200)\n        exp = GradCAM()\n        image = images[id]\n        mask = masks[id]\n        pred_mask = self.model.predict(image[np.newaxis,...])\n        cam = exp.explain(\n            validation_data=(image[np.newaxis,...], mask),\n            class_index=1,\n            layer_name='Attention4',\n            model=self.model\n        )\n\n        plt.figure(figsize=(10,5))\n\n        plt.subplot(1,3,1)\n        plt.title(\"Original Mask\")\n        show_mask(image, mask, cmap='copper')\n\n        plt.subplot(1,3,2)\n        plt.title(\"Predicted Mask\")\n        show_mask(image, pred_mask, cmap='copper')\n\n        plt.subplot(1,3,3)\n        show_image(cam,title=\"GradCAM\")\n\n        plt.tight_layout()\n        plt.show()","metadata":{"id":"IsCTVw0tNeZg","execution":{"iopub.status.busy":"2022-09-05T03:02:26.741172Z","iopub.execute_input":"2022-09-05T03:02:26.741458Z","iopub.status.idle":"2022-09-05T03:02:26.750009Z","shell.execute_reply.started":"2022-09-05T03:02:26.741433Z","shell.execute_reply":"2022-09-05T03:02:26.748822Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Attention UNet**","metadata":{}},{"cell_type":"code","source":"# Inputs\ninput_layer = Input(shape=images.shape[-3:])\n\n# Encoder\np1, c1 = EncoderBlock(32,0.1, name=\"Encoder1\")(input_layer)\np2, c2 = EncoderBlock(64,0.1, name=\"Encoder2\")(p1)\np3, c3 = EncoderBlock(128,0.2, name=\"Encoder3\")(p2)\np4, c4 = EncoderBlock(256,0.2, name=\"Encoder4\")(p3)\n\n# Encoding\nencoding = EncoderBlock(512,0.3, pooling=False, name=\"Encoding\")(p4)\n\n# Attention + Decoder\n\na1 = AttentionGate(256, bn=True, name=\"Attention1\")([encoding, c4])\nd1 = DecoderBlock(256,0.2, name=\"Decoder1\")([encoding, a1])\n\na2 = AttentionGate(128, bn=True, name=\"Attention2\")([d1, c3])\nd2 = DecoderBlock(128,0.2, name=\"Decoder2\")([d1, a2])\n\na3 = AttentionGate(64, bn=True, name=\"Attention3\")([d2, c2])\nd3 = DecoderBlock(64,0.1, name=\"Decoder3\")([d2, a3])\n\n\na4 = AttentionGate(32, bn=True, name=\"Attention4\")([d3, c1])\nd4 = DecoderBlock(32,0.1, name=\"Decoder4\")([d3, a4])\n\n# Output \noutput_layer = Conv2D(1, kernel_size=1, activation='sigmoid', padding='same')(d4)\n\n# Model\nmodel = Model(\n    inputs=[input_layer],\n    outputs=[output_layer]\n)\n\n# Compile\nmodel.compile(\n    loss='binary_crossentropy',\n    optimizer='adam',\n    metrics=['accuracy', MeanIoU(num_classes=2, name='IoU')]\n)\n\n# Callbacks\ncb = [\n    # EarlyStopping(patience=3, restore_best_weight=True), # With Segmentation I trust on eyes rather than on metrics\n    ModelCheckpoint(\"AttentionCustomUNet.h5\", save_best_only=True),\n    ShowProgress()\n]","metadata":{"id":"JUqEssMcQ8me","execution":{"iopub.status.busy":"2022-09-05T03:02:26.751775Z","iopub.execute_input":"2022-09-05T03:02:26.752223Z","iopub.status.idle":"2022-09-05T03:02:27.32494Z","shell.execute_reply.started":"2022-09-05T03:02:26.752189Z","shell.execute_reply":"2022-09-05T03:02:27.323986Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Training**","metadata":{}},{"cell_type":"code","source":"# Config Training\nBATCH_SIZE = 8\nSPE = len(images)//BATCH_SIZE\n\n# Training\nresults = model.fit(\n    images, masks,\n    validation_split=0.2,\n    epochs=20, # 15 will be enough for a good Model for better model go with 20+\n    steps_per_epoch=SPE,\n    batch_size=BATCH_SIZE,\n    callbacks=cb\n)","metadata":{"id":"MpBP0XH6RJEY","outputId":"2a4bf608-8f89-4c13-81f8-b1ee04e8a856","execution":{"iopub.status.busy":"2022-09-05T03:13:21.53732Z","iopub.execute_input":"2022-09-05T03:13:21.538381Z","iopub.status.idle":"2022-09-05T03:17:44.983339Z","shell.execute_reply.started":"2022-09-05T03:13:21.538333Z","shell.execute_reply":"2022-09-05T03:17:44.98227Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Observations :**\n\n* After **12 epochs** model started outputting what we needed.\n* The model was easily able to detect **black round spots but fails when the shape is irregular**(Not the case with current model because it is trained with hight SPE). \n\n* It also gets confused between the dark areas, which makes sense.\n\n---\n**Suggestion :**\n* Do training in chunks of **20 Epochs**, this will give you a good control **over model and the model will also perform well**.\n\n* Here the model is trained on 17 + 17 + 17 = 51 Epochs.\n\n* If you give the model a closer look n different images you will find that the model fails at some images, but I can garantee that 9/10 such images would be so tough that even a human will not be a able to detect as many parts of the image look the same.\n","metadata":{"id":"3nJgacMfUMro"}},{"cell_type":"markdown","source":"# **Evaluation**","metadata":{}},{"cell_type":"code","source":"loss, accuracy, iou, val_loss, val_accuracy, val_iou = results.history.values()","metadata":{"id":"m5uV8wgMWlao","execution":{"iopub.status.busy":"2022-09-05T03:17:44.988759Z","iopub.execute_input":"2022-09-05T03:17:44.989069Z","iopub.status.idle":"2022-09-05T03:17:44.994365Z","shell.execute_reply.started":"2022-09-05T03:17:44.989041Z","shell.execute_reply":"2022-09-05T03:17:44.993398Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(20,8))\n\nplt.subplot(1,3,1)\nplt.title(\"Model Loss\")\nplt.plot(loss, label=\"Training\")\nplt.plot(val_loss, label=\"Validtion\")\nplt.legend()\nplt.grid()\n\nplt.subplot(1,3,2)\nplt.title(\"Model Accuracy\")\nplt.plot(accuracy, label=\"Training\")\nplt.plot(val_accuracy, label=\"Validtion\")\nplt.legend()\nplt.grid()\n\nplt.subplot(1,3,3)\nplt.title(\"Model IoU\")\nplt.plot(iou, label=\"Training\")\nplt.plot(val_iou, label=\"Validtion\")\nplt.legend()\nplt.grid()\n\nplt.show()","metadata":{"id":"KUgo9t-bW2aH","outputId":"e7672a19-48bc-407e-c4c9-c277c253a730","execution":{"iopub.status.busy":"2022-09-05T03:17:44.99582Z","iopub.execute_input":"2022-09-05T03:17:44.996888Z","iopub.status.idle":"2022-09-05T03:17:45.494628Z","shell.execute_reply.started":"2022-09-05T03:17:44.99685Z","shell.execute_reply":"2022-09-05T03:17:45.49377Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Suprisingly the results on **Validation Data** are **way better** than the results on **Trainind Data** on **IoU**, this may indicate that the **model can perform way better** than what it can do at the current point. The **Loss is not Perfect** it increases in the last but the model constructions are loooking perfect as this point, that's why **I believe in what I see**. This model seems promising, let's try it on some Images.","metadata":{"id":"zfhLm2LOXvOw"}},{"cell_type":"code","source":"plt.figure(figsize=(20,25))\nn=0\nfor i in range(1,(5*3)+1):\n    plt.subplot(5,3,i)\n    if n==0:\n        id = np.random.randint(len(images))\n        image = images[id]\n        mask = masks[id]\n        pred_mask = model.predict(image[np.newaxis,...])\n\n        plt.title(\"Original Mask\")\n        show_mask(image, mask)\n        n+=1\n    elif n==1:\n        plt.title(\"Predicted Mask\")\n        show_mask(image, pred_mask)\n        n+=1\n    elif n==2:\n        pred_mask = (pred_mask>0.5).astype('float')\n        plt.title(\"Processed Mask\")\n        show_mask(image, pred_mask)\n        n=0\nplt.tight_layout()\nplt.show()","metadata":{"id":"fvjqCPIMW2XG","outputId":"070d77c1-5f7a-4261-f74f-9b70484f58fc","execution":{"iopub.status.busy":"2022-09-05T03:19:30.271081Z","iopub.execute_input":"2022-09-05T03:19:30.272136Z","iopub.status.idle":"2022-09-05T03:19:32.385401Z","shell.execute_reply.started":"2022-09-05T03:19:30.272095Z","shell.execute_reply":"2022-09-05T03:19:32.384429Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The results totally convincing. If you have any suggestions please let me know 👍. **Thanks !!**","metadata":{}}]}